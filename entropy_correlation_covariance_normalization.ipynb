{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def entropy4(labels, base=None):\n",
    "  value,counts = np.unique(labels, return_counts=True)\n",
    "  norm_counts = counts / counts.sum()\n",
    "  base = e if base is None else base\n",
    "  return -(norm_counts * np.log(norm_counts)/np.log(base)).sum()\n",
    "\n",
    "\n",
    "def remaining(labels, base=None):\n",
    "  value,counts = np.unique(labels, return_counts=True)\n",
    "  norm_counts = counts / counts.sum()\n",
    "  base = e if base is None else base\n",
    "  return -(norm_counts * np.log(norm_counts)/np.log(base)).sum()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852281360342516"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy4([1,0,0,1,0,0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {\n",
    "    \"Attribute1\": ['F', 'T', 'T', 'F', 'F','T','T'],\n",
    "    \"Attribute2\": ['H', 'M', 'H', 'H', 'L','H','H'],\n",
    "    \"Attribute3\": ['H', 'L', 'M', 'M', 'H','HH','H'],\n",
    "    \"Label\": ['A', 'B', 'B', 'A', 'C','C','A']\n",
    "}\n",
    "attr1_en = LabelEncoder()\n",
    "attr2_en = LabelEncoder()\n",
    "attr3_en = LabelEncoder()\n",
    "label_en = LabelEncoder()\n",
    "\n",
    "from scipy.stats import entropy\n",
    "df = pd.DataFrame(data2)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attr1_en'] = attr1_en.fit_transform(df['Attribute1'])\n",
    "df['attr2_en'] = attr2_en.fit_transform(df['Attribute2'])\n",
    "df['attr3_en'] = attr3_en.fit_transform(df['Attribute3'])\n",
    "df['label_en'] = label_en.fit_transform(df['Label'])\n",
    "\n",
    "#final = df.drop(['Attribute1','Attribute2','Attribute3','Label','attr1_en','attr2_en','attr3_en'],axis='columns')\n",
    "final = df.drop(['Attribute1','Attribute2','Attribute3','Label'],axis='columns')\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy4(final['label_en'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {\n",
    "    \"Attribute1\": ['T', 'T', 'T', 'F', 'F','F'],\n",
    "    \"Attribute2\": ['F', 'T', 'T', 'T', 'F','F'],\n",
    "    \"Attribute3\": ['T', 'F', 'F', 'T', 'F','F'],\n",
    "    \"Label\": ['S', 'S', 'S', 'H', 'H','H']\n",
    "}\n",
    "attr1_en = LabelEncoder()\n",
    "attr2_en = LabelEncoder()\n",
    "attr3_en = LabelEncoder()\n",
    "label_en = LabelEncoder()\n",
    "\n",
    "from scipy.stats import entropy\n",
    "df = pd.DataFrame(data2)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attr1_en'] = attr1_en.fit_transform(df['Attribute1'])\n",
    "df['attr2_en'] = attr2_en.fit_transform(df['Attribute2'])\n",
    "df['attr3_en'] = attr3_en.fit_transform(df['Attribute3'])\n",
    "df['label_en'] = label_en.fit_transform(df['Label'])\n",
    "\n",
    "#final = df.drop(['Attribute1','Attribute2','Attribute3','Label','attr1_en','attr2_en','attr3_en'],axis='columns')\n",
    "final = df.drop(['Attribute1','Attribute2','Attribute3','Label'],axis='columns')\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Entropy using User defined fucntion\n",
    "entropy4(final['attr1_en'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy using python lib\n",
    "entropy(final.set_index('attr1_en').squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(final.set_index('attr2_en').squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(final.set_index('attr3_en').squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def NormalizeData(data,range_min,range_max):\n",
    "    \n",
    "    normalized_value = (((data - np.min(data)) / (np.max(data) - np.min(data)) ) * (range_max-range_min)) + range_min\n",
    "    return (normalized_value)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = [2,3.5,4,4.5,3,3.5,4,3,3.5,3,5,4.5,3.5,4,2,4.5,2,4.5,1,3]\n",
    "Y = [0,12,10,21,12,15,16,18,18,16,19,6,8,22,6,8,10,30,1,4]\n",
    "\n",
    "\n",
    "# 0 for range min and 1 for range max\n",
    "normalized_x = np.round(NormalizeData(X,0,1),2)\n",
    "normalized_y = np.round(NormalizeData(Y,0,1),2)\n",
    "print(normalized_x )\n",
    "print(normalized_y )\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(111)\n",
    "ax.plot(normalized_x,normalized_y)\n",
    "#for xy in zip(normalized_x,normalized_y):                                       # <--\n",
    "    #ax.annotate('(%s, %s)' % xy, xy=xy, textcoords='data') # <--\n",
    "\n",
    "plt.scatter(normalized_x, normalized_y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array([295,890,406,293,651])\n",
    "\n",
    "norm_data = NormalizeData(X1,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(norm_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(norm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, y):\n",
    "    # Finding the mean of the series x and y\n",
    "    mean_x = sum(x)/float(len(x))\n",
    "    mean_y = sum(y)/float(len(y))\n",
    "    # Subtracting mean from the individual elements\n",
    "    sub_x = [i - mean_x for i in x]\n",
    "    sub_y = [i - mean_y for i in y]\n",
    "    numerator = sum([sub_x[i]*sub_y[i] for i in range(len(sub_x))])\n",
    "    denominator = len(x)-1\n",
    "    cov = numerator/denominator\n",
    "    return cov\n",
    "\n",
    "def correlation(x, y):\n",
    "    # Finding the mean of the series x and y\n",
    "    mean_x = sum(x)/float(len(x))\n",
    "    mean_y = sum(y)/float(len(y))\n",
    "    # Subtracting mean from the individual elements\n",
    "    sub_x = [i-mean_x for i in x]\n",
    "    sub_y = [i-mean_y for i in y]\n",
    "    # covariance for x and y\n",
    "    numerator = sum([sub_x[i]*sub_y[i] for i in range(len(sub_x))])\n",
    "    # Standard Deviation of x and y\n",
    "    std_deviation_x = sum([sub_x[i]**2.0 for i in range(len(sub_x))])\n",
    "    std_deviation_y = sum([sub_y[i]**2.0 for i in range(len(sub_y))])\n",
    "    # squaring by 0.5 to find the square root\n",
    "    denominator = (std_deviation_x*std_deviation_y)**0.5 # short but equivalent to (std_deviation_x**0.5) * (std_deviation_y**0.5)\n",
    "    cor = numerator/denominator\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = [30,95,31,32,76]\n",
    "x = [1,2,3,5,6]\n",
    "\n",
    "covariance(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
